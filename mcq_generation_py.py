# -*- coding: utf-8 -*-
"""MCQ_generation.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OMUKONLKSi8hhscbs8699pdlsH5onOpo
"""

import requests
import json
import logging
import os
import re
import time
import random
from datetime import datetime
from bs4 import BeautifulSoup
import openai
from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By


# Set up logging— for debugging!
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("mcq_generator.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def get_api_key():
    """Get OpenAI API key from environment variable or prompt user"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        api_key = input("Enter your OpenAI API key: ")
    print(f"Retrieved API key starts with: {api_key[:5]}...")  # Print first 5 characters for security
    return api_key

@retry(
    wait=wait_random_exponential(min=1, max=60),
    stop=stop_after_attempt(3),
    retry=retry_if_exception_type((openai.RateLimitError, openai.APIError))
)
def openai_chat(prompt, api_key, model="gpt-4-turbo-preview"):
    """
    Uses OpenAI's chat models to generate JSON responses.

    Args:
        prompt (str): The prompt for the model
        api_key (str): OpenAI API key
        model (str): Model to use, defaults to gpt-4-turbo-preview

    Returns:
        dict: Parsed JSON response or None on error
    """
    try:
        openai.api_key = api_key
        response = openai.chat.completions.create(
            model=model,
            messages=[{"role": "system", "content": "You are a helpful assistant that specializes in education standards and creating learning materials. Always respond with valid JSON."},
                      {"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0.5,  # Lower temperature for more consistent results
            max_tokens=2500
        )
        content = response.choices[0].message.content
        return json.loads(content)
    except openai.RateLimitError as e:
        logger.warning(f"Rate limit exceeded: {e}. Retrying...")
        raise
    except openai.APIError as e:
        logger.warning(f"API error: {e}. Retrying...")
        raise
    except Exception as e:
        logger.error(f"Error calling OpenAI API: {e}")
        logger.error(f"Traceback: {type(e).__name__}: {e}")
        return None

class CommonCoreMCQGenerator:
    """
    Main class Generates and validates Multiple Choice Questions(MCQs) based on Common Core Math Standards!

    This class handles the entire workflow:
    1. Fetches standards from the Common Core website (or uses fallback methods)
    2. Parses and extracts the standards
    3. Generates MCQs using OpenAI's models
    4. Validates the generated MCQs for quality assurance
    """

    def __init__(self, api_key=None, grade=5):
        """
        Initialize the MCQ generator.

        Args:
            api_key (str, optional): OpenAI API key. If None, will try to get from environment
            grade (int, optional): Grade level to target. Defaults to 5.
        """
        self.api_key = api_key or get_api_key()
        self.grade = grade
        # Added specific path for grade 5
        self.base_url = f"https://www.thecorestandards.org/Math/Content/{grade}/"
        self.standards = {}  # Will store extracted standards
        self.mcqs = []       # Will store generated MCQs

        # Domains I care about most— feel free to change this
        self.priorityDomains = [
            "Operations & Algebraic Thinking",
            "Number & Operations in Base Ten",
            "Geometry"
        ]

        # Keep track of extraction method used for logging
        self.extraction_method = None

        # Initialize user agents for rotation
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Safari/605.1.15',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:90.0) Gecko/20100101 Firefox/90.0',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'
        ]

    '''
    def fetch_standards_page(self):
        """
        Fetching the HTML content from the Common Core Math standards page.

        Returns:
            str: HTML content or None on failure
        """
        try:
            # Rotate user agents to avoid detection
            user_agent = random.choice(self.user_agents)

            # Use more browser-like headers to avoid being blocked
            headers = {
                'User-Agent': user_agent,
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Cache-Control': 'max-age=0',
                'Referer': 'https://www.thecorestandards.org/'
            }

            logger.info(f"Attempting to fetch content from {self.base_url}")

            # Add a randomized delay to be more human-like
            time.sleep(random.uniform(2, 5))

            # Try different approach - first get the main page to establish cookies
            session = requests.Session()
            main_page = session.get('https://www.thecorestandards.org/',
                                    headers=headers,
                                    timeout=15)

            # Then request the standards page using the same session
            time.sleep(random.uniform(1, 3))
            response = session.get(self.base_url,
                                  headers=headers,
                                  timeout=15)

            if response.status_code == 200:
                logger.info(f"Successfully fetched content from {self.base_url}")
                return response.text
            else:
                logger.error(f"Failed to fetch content: HTTP {response.status_code}")
                # Try an alternative URL format
                alt_url = f"https://www.thecorestandards.org/Math/Content/Grade{self.grade}/"
                logger.info(f"Trying alternative URL: {alt_url}")

                time.sleep(random.uniform(1, 3))
                response = session.get(alt_url, headers=headers, timeout=15)

                if response.status_code == 200:
                    logger.info(f"Successfully fetched content from alternative URL")
                    return response.text

                logger.error(f"All fetch attempts failed with HTTP {response.status_code}")
                return None

        except requests.RequestException as e:
            logger.error(f"Error fetching content: {e}")
            return None

    '''

    def fetch_standards_page(self):
        """
        Using Selenium to grab the content from webpage — the requests kept getting blocked.

        Returns:
            str: HTML content or None on failure
        """
        try:
            # Set up Selenium with headless Chrome
            options = Options()
            options.add_argument('--headless')  # # Switched to Selenium after requests kept getting 403 errors—needed a browser-like approach.
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-blink-features=AutomationControlled')  # Avoid detection

            # Set a realistic User-Agent
            options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')

            # Initialize the driver
            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

            logger.info(f"Attempting to fetch content from {self.base_url}")

            # First we load the main page to establish cookies
            driver.get('https://www.thecorestandards.org/')
            time.sleep(3)

            # Then navigate to the standards page
            driver.get(self.base_url)

            # Wait longer for the page to load
            time.sleep(10)

            # Get the fully rendered HTML
            html = driver.page_source

            if "403 Forbidden" not in html:  # Basic check for success
                logger.info(f"Successfully fetched content from {self.base_url}")
                driver.quit()
                return html
            else:
                # Try alternative URL format
                logger.error(f"Failed to fetch content: HTTP 403 detected in response")
                alt_url = f"https://www.thecorestandards.org/Math/Content/Grade{self.grade}/"
                logger.info(f"Trying alternative URL: {alt_url}")

                driver.get(alt_url)
                time.sleep(10)
                html = driver.page_source

                if "403 Forbidden" not in html:
                    logger.info(f"Successfully fetched content from alternative URL")
                    driver.quit()
                    return html

                driver.quit()
                return None

        except Exception as e:
            logger.error(f"Error fetching content with Selenium: {e}")
            if 'driver' in locals():
                driver.quit()
            return None

    def generate_standards_with_llm(self):
        """
        Fallback: ask the LLM to make standards if the site’s down

        Returns:
            dict: Generated standards by domain
        """
        logger.info("Using LLM to generate Common Core standards (fallback method)")
        self.extraction_method = "llm_generation"

        prompt = f"""
        Give me Grade {self.grade} Common Core Math standards in JSON—domains, IDs, text, the works!.

        I need exact representations of the actual standards though including:
        1. Domain names (e.g., "Operations & Algebraic Thinking", "Number & Operations in Base Ten")
        2. Standard IDs using the proper format (e.g., "{self.grade}.OA.A.1", "{self.grade}.NBT.B.5")
        3. The complete text of each standard

        Also, could you format your response as a JSON object where:
        - Keys are domain names
        - Values are objects with standard IDs as keys and standard descriptions as values

        Furthermore, for Grade {self.grade}, please be sure to cover ALL DOMAINS and standards in the Common Core Math:
        - Operations & Algebraic Thinking (OA)
        - Number & Operations in Base Ten (NBT)
        - Number & Operations—Fractions (NF)
        - Measurement & Data (MD)
        - Geometry (G)

        Finally, include all substandards (e.g., 5.NF.B.7.a, 5.NF.B.7.b, 5.NF.B.7.c). Thank You!
        """

        try:
            response = openai_chat(prompt, self.api_key)
            if response:
                # Log how many standards were generated
                total_standards = sum(len(standards) for standards in response.values())
                logger.info(f"Generated {total_standards} standards across {len(response)} domains using LLM")
                return response
            else:
                logger.error("Failed to generate standards using LLM")
                return self.use_hardcoded_standards()
        except Exception as e:
            logger.error(f"Error generating standards with LLM: {e}")
            return self.use_hardcoded_standards()

    def use_hardcoded_standards(self):
        """
        Using hardcoded standards as a last resort fallback(WILL be removed later!).
        These are actual Grade 5 standards from common core!.

        Returns:
            dict: Hardcoded standards
        """
        logger.info("Using hardcoded standards as final fallback")
        self.extraction_method = "hardcoded"

        # Complete set of Grade 5 standards
        return {
            "Operations & Algebraic Thinking": {
                "5.OA.A.1": "Use parentheses, brackets, or braces in numerical expressions, and evaluate expressions with these symbols.",
                "5.OA.A.2": "Write simple expressions that record calculations with numbers, and interpret numerical expressions without evaluating them.",
                "5.OA.B.3": "Generate two numerical patterns using two given rules. Identify apparent relationships between corresponding terms. Form ordered pairs consisting of corresponding terms from the two patterns, and graph the ordered pairs on a coordinate plane."
            },
            "Number & Operations in Base Ten": {
                "5.NBT.A.1": "Recognize that in a multi-digit number, a digit in one place represents 10 times as much as it represents in the place to its right and 1/10 of what it represents in the place to its left.",
                "5.NBT.A.2": "Explain patterns in the number of zeros of the product when multiplying a number by powers of 10, and explain patterns in the placement of the decimal point when a decimal is multiplied or divided by a power of 10.",
                "5.NBT.A.3": "Read, write, and compare decimals to thousandths.",
                "5.NBT.A.3.a": "Read and write decimals to thousandths using base-ten numerals, number names, and expanded form.",
                "5.NBT.A.3.b": "Compare two decimals to thousandths based on meanings of the digits in each place, using >, =, and < symbols to record the results of comparisons.",
                "5.NBT.A.4": "Use place value understanding to round decimals to any place.",
                "5.NBT.B.5": "Fluently multiply multi-digit whole numbers using the standard algorithm.",
                "5.NBT.B.6": "Find whole-number quotients of whole numbers with up to four-digit dividends and two-digit divisors, using strategies based on place value, the properties of operations, and/or the relationship between multiplication and division. Illustrate and explain the calculation by using equations, rectangular arrays, and/or area models.",
                "5.NBT.B.7": "Add, subtract, multiply, and divide decimals to hundredths, using concrete models or drawings and strategies based on place value, properties of operations, and/or the relationship between addition and subtraction; relate the strategy to a written method and explain the reasoning used."
            },
            "Number & Operations—Fractions": {
                "5.NF.A.1": "Add and subtract fractions with unlike denominators (including mixed numbers) by replacing given fractions with equivalent fractions in such a way as to produce an equivalent sum or difference of fractions with like denominators.",
                "5.NF.A.2": "Solve word problems involving addition and subtraction of fractions referring to the same whole, including cases of unlike denominators.",
                "5.NF.B.3": "Interpret a fraction as division of the numerator by the denominator (a/b = a ÷ b). Solve word problems involving division of whole numbers leading to answers in the form of fractions or mixed numbers.",
                "5.NF.B.4": "Apply and extend previous understandings of multiplication to multiply a fraction or whole number by a fraction.",
                "5.NF.B.4.a": "Interpret the product (a/b) × q as a parts of a partition of q into b equal parts; equivalently, as the result of a sequence of operations a × q ÷ b.",
                "5.NF.B.4.b": "Find the area of a rectangle with fractional side lengths by tiling it with unit squares of the appropriate unit fraction side lengths, and show that the area is the same as would be found by multiplying the side lengths.",
                "5.NF.B.5": "Interpret multiplication as scaling (resizing), by comparing the size of a product to the size of one factor on the basis of the size of the other factor, without performing the indicated multiplication.",
                "5.NF.B.6": "Solve real world problems involving multiplication of fractions and mixed numbers.",
                "5.NF.B.7": "Apply and extend previous understandings of division to divide unit fractions by whole numbers and whole numbers by unit fractions.",
                "5.NF.B.7.a": "Interpret division of a unit fraction by a non-zero whole number, and compute such quotients.",
                "5.NF.B.7.b": "Interpret division of a whole number by a unit fraction, and compute such quotients.",
                "5.NF.B.7.c": "Solve real world problems involving division of unit fractions by non-zero whole numbers and division of whole numbers by unit fractions."
            },
            "Measurement & Data": {
                "5.MD.A.1": "Convert among different-sized standard measurement units within a given measurement system, and use these conversions in solving multi-step, real world problems.",
                "5.MD.B.2": "Make a line plot to display a data set of measurements in fractions of a unit (1/2, 1/4, 1/8). Use operations on fractions for this grade to solve problems involving information presented in line plots.",
                "5.MD.C.3": "Recognize volume as an attribute of solid figures and understand concepts of volume measurement.",
                "5.MD.C.3.a": "A cube with side length 1 unit, called a 'unit cube,' is said to have 'one cubic unit' of volume, and can be used to measure volume.",
                "5.MD.C.3.b": "A solid figure which can be packed without gaps or overlaps using n unit cubes is said to have a volume of n cubic units.",
                "5.MD.C.4": "Measure volumes by counting unit cubes, using cubic cm, cubic in, cubic ft, and improvised units.",
                "5.MD.C.5": "Relate volume to the operations of multiplication and addition and solve real world and mathematical problems involving volume.",
                "5.MD.C.5.a": "Find the volume of a right rectangular prism with whole-number side lengths by packing it with unit cubes, and show that the volume is the same as would be found by multiplying the edge lengths, equivalently by multiplying the height by the area of the base.",
                "5.MD.C.5.b": "Apply the formulas V = l × w × h and V = b × h for rectangular prisms to find volumes of right rectangular prisms with whole-number edge lengths in the context of solving real world and mathematical problems.",
                "5.MD.C.5.c": "Recognize volume as additive. Find volumes of solid figures composed of two non-overlapping right rectangular prisms by adding the volumes of the non-overlapping parts, applying this technique to solve real world problems."
            },
            "Geometry": {
                "5.G.A.1": "Use a pair of perpendicular number lines, called axes, to define a coordinate system, with the intersection of the lines (the origin) arranged to coincide with the 0 on each line and a given point in the plane located by using an ordered pair of numbers, called its coordinates. Understand that the first number indicates how far to travel from the origin in the direction of one axis, and the second number indicates how far to travel in the direction of the second axis, with the convention that the names of the two axes and the coordinates correspond.",
                "5.G.A.2": "Represent real world and mathematical problems by graphing points in the first quadrant of the coordinate plane, and interpret coordinate values of points in the context of the situation.",
                "5.G.B.3": "Understand that attributes belonging to a category of two-dimensional figures also belong to all subcategories of that category.",
                "5.G.B.4": "Classify two-dimensional figures in a hierarchy based on properties."
            }
        }

    def parse_standard_id(self, raw_id):
        """
        Convert various formats of standard IDs to a consistent format (5.X.Y.Z).

        Args:
            raw_id (str): Raw standard ID from the HTML

        Returns:
            str: Normalized standard ID
        """
        # Already in the right format (5.X.Y.Z)
        if re.match(r'^\d+\.\w+\.\w+\.\d+(\.\w+)?$', raw_id):
            return raw_id

        # CCSS.Math.Content format
        ccss_match = re.match(r'CCSS\.Math\.Content\.(\d+\.\w+\.\w+\.\d+(?:\.\w+)?)', raw_id)
        if ccss_match:
            return ccss_match.group(1)

        # Add missing cluster (A, B, C) if needed
        if re.match(r'^\d+\.\w+\.\d+(\.\w+)?$', raw_id):
            parts = raw_id.split('.')
            if len(parts) >= 3:
                # Insert an 'A' for the first cluster, 'B' for second, etc.
                cluster = chr(64 + int(parts[2][0]))  # 1->A, 2->B, etc.
                return f"{parts[0]}.{parts[1]}.{cluster}.{parts[2]}"

        # Can't normalize, return as is
        return raw_id


    def extract_standards_with_soup(self, html_content):
        """
        Extract standards using BeautifulSoup.

        Args:
            html_content (str): HTML content from the standards page

        Returns:
            dict: Extracted standards by domain
        """
        try:
            self.extraction_method = "web_scraping"
            soup = BeautifulSoup(html_content, 'html.parser')

            # Check what I actually got
            page_title = soup.title.text if soup.title else "No title found"
            logger.info(f"Page title: {page_title}")

            # Save a sample of the HTML for inspection
            with open("sample_page.html", "w", encoding="utf-8") as f:
                f.write(str(soup.prettify()[:10000]))

            standards_dict = {}
            current_domain = "Unknown Domain"

            # Look for the main content area
            main_content = soup.find('div', class_='main-content') or soup.find('div', id='main-content')
            if not main_content:
                main_content = soup.find('div', class_='content') or soup

            # Find all headers that might indicate domains
            domain_headers = main_content.find_all(['h2', 'h3', 'h4'])

            for header in domain_headers:
                header_text = header.get_text().strip()
                # Check if this looks like a domain header
                if any(keyword in header_text.lower() for keyword in ['operations', 'number', 'measurement', 'geometry', 'data', 'algebraic', 'fractions']):
                    current_domain = header_text
                    if current_domain not in standards_dict:
                        standards_dict[current_domain] = {}

                    # Look for standards that follow this header
                    next_element = header.find_next()
                    while next_element and next_element.name not in ['h2', 'h3', 'h4']:
                        # Check if this element contains a standard
                        element_text = next_element.get_text().strip()

                        # Look for standard IDs in the CCSS.Math.Content.5.X.Y.Z format
                        std_matches = re.findall(r'CCSS\.Math\.Content\.(5\.\w+\.\w+\.\d+(?:\.\w+)?)', element_text)

                        # Also look for simpler 5.X.Y.Z format
                        if not std_matches:
                            std_matches = re.findall(r'(5\.\w+\.\w+\.\d+(?:\.\w+)?)', element_text)

                        for std_id in std_matches:
                            # Extract the text after the standard ID
                            parts = re.split(r'CCSS\.Math\.Content\.5\.\w+\.\w+\.\d+(?:\.\w+)?|5\.\w+\.\w+\.\d+(?:\.\w+)?', element_text, 1)
                            if len(parts) > 1:
                                std_text = parts[1].strip()
                                # Convert standard ID format for consistency
                                if not std_id.startswith('5.'):
                                    std_id = re.sub(r'CCSS\.Math\.Content\.', '', std_id)
                                standards_dict[current_domain][std_id] = std_text

                        next_element = next_element.find_next()

            # If we don't have enough standards, try a more targeted approach
            if not standards_dict or sum(len(standards) for standards in standards_dict.values()) < 5:
                logger.info("Initial extraction yielded few results, trying targeted approach")

                # Find all paragraphs containing standard IDs
                all_elements = main_content.find_all(['p', 'li', 'div'])

                for element in all_elements:
                    text = element.get_text().strip()

                    # Check for standard IDs in both formats
                    std_matches = re.findall(r'CCSS\.Math\.Content\.(5\.\w+\.\w+\.\d+(?:\.\w+)?)', text)
                    if not std_matches:
                        std_matches = re.findall(r'(5\.\w+\.\w+\.\d+(?:\.\w+)?)', text)

                    for std_id in std_matches:
                        # Determine the domain from the standard ID
                        domain_code = std_id.split('.')[1]  # Extract OA, NBT, NF, etc.
                        domain_map = {
                            'OA': 'Operations & Algebraic Thinking',
                            'NBT': 'Number & Operations in Base Ten',
                            'NF': 'Number & Operations—Fractions',
                            'MD': 'Measurement & Data',
                            'G': 'Geometry'
                        }
                        domain_name = domain_map.get(domain_code, f"Domain {domain_code}")

                        if domain_name not in standards_dict:
                            standards_dict[domain_name] = {}

                        # Extract standard text
                        parts = re.split(r'CCSS\.Math\.Content\.5\.\w+\.\w+\.\d+(?:\.\w+)?|5\.\w+\.\w+\.\d+(?:\.\w+)?', text, 1)
                        if len(parts) > 1:
                            std_text = parts[1].strip()
                            # Convert standard ID format
                            if not std_id.startswith('5.'):
                                std_id = re.sub(r'CCSS\.Math\.Content\.', '', std_id)
                            standards_dict[domain_name][std_id] = std_text

            # If we found standards, return them
            if standards_dict and sum(len(standards) for standards in standards_dict.values()) >= 3:
                logger.info(f"Successfully extracted {sum(len(stds) for stds in standards_dict.values())} standards from {len(standards_dict)} domains")
                return standards_dict
            else:
                # Fall back to LLM parsing
                logger.warning("BeautifulSoup parsing didn't extract enough standards, falling back to LLM")
                return self.extract_standards_with_llm(html_content)

        except Exception as e:
            logger.error(f"Error parsing HTML with BeautifulSoup: {e}")
            logger.error(f"Traceback: {type(e).__name__}: {e}")
            # Fall back to LLM parsing
            return self.extract_standards_with_llm(html_content)

    def extract_standards_with_llm(self, html_content):
        """
        Extract standards using LLM as backup when HTML parsing fails.

        Args:
            html_content (str): HTML content from the standards page

        Returns:
            dict: Extracted standards by domain
        """
        self.extraction_method = "llm_extraction"

        # Take a reasonable chunk of the HTML, focusing on the content area if possible
        content_chunk = html_content
        soup = BeautifulSoup(html_content, 'html.parser')

        # Try to find the main content area
        content_area = soup.find('div', id=lambda x: x and ('content' in x or 'main' in x))
        if content_area:
            content_chunk = str(content_area)

        # Keep it to a reasonable size
        content_sample = content_chunk[:8000]

        # Improved prompt with more specific instructions
        prompt = f"""
        Extract all Grade {self.grade} Math standards from this HTML content from the Common Core website.

        Each standard should include:
        1. Domain name (e.g., "Operations & Algebraic Thinking")
        2. Standard ID (e.g., "{self.grade}.OA.A.1") including all substandards (like {self.grade}.NF.B.7.a)
        3. The complete text description of each standard

        Ignore navigation elements, headers, footers, and anything that isn't an actual standard.

        Format your response as a JSON object where:
        - Keys are domain names
        - Values are objects with standard IDs as keys and standard descriptions as values

        HTML Content (partial):
        {content_sample}

        If the HTML appears incomplete or doesn't contain standards, create accurate Common Core Math standards for Grade {self.grade} based on your knowledge.
        """

        try:
            response = openai_chat(prompt, self.api_key)
            if response:
                # Log how many standards were extracted
                total_standards = sum(len(standards) for standards in response.values())
                logger.info(f"Extracted {total_standards} standards across {len(response)} domains using LLM")
                return response
            else:
                logger.error("Failed to extract standards using LLM")
                # Last resort: generate standards from scratch
                return self.generate_standards_with_llm()
        except Exception as e:
            logger.error(f"Error extracting standards with LLM: {e}")
            return self.generate_standards_with_llm()

    def clean_standards(self, standards):
        """
        Clean up and normalize extracted standards.

        Args:
            standards (dict): Raw extracted standards

        Returns:
            dict: Cleaned standards with consistent formatting
        """
        cleaned = {}

        for domain, domain_standards in standards.items():
            # Clean domain name (remove extra whitespace, normalize)
            clean_domain = re.sub(r'\s+', ' ', domain).strip()

            # Skip empty domains
            if not clean_domain:
                continue

            # Remove any prefixes like "Domain: " that might appear
            clean_domain = re.sub(r'^(Domain|Category|Section):\s*', '', clean_domain, flags=re.I)

            # Initialize domain if it's new
            if clean_domain not in cleaned:
                cleaned[clean_domain] = {}

            for std_id, std_text in domain_standards.items():
                # Skip if either part is empty
                if not std_id or not std_text:
                    continue

                # Clean standard ID (remove whitespace)
                clean_id = re.sub(r'\s+', '', std_id).strip()

                # Make sure it follows the expected format (e.g., "5.OA.A.1")
                if not re.match(r'^\d+\.\w+\.\w+\.\d+(\.\w+)?$', clean_id):
                    # Try to fix common issues
                    if re.match(r'^\d+\.\w+\.\d+(\.\w+)?$', clean_id):
                        # Missing middle level, try to infer (usually A, B, C)
                        parts = clean_id.split('.')
                        if len(parts) >= 3:
                            # Insert an 'A' for the first cluster, 'B' for second, etc.
                            cluster = chr(64 + int(parts[2][0]))  # 1->A, 2->B, etc.
                            clean_id = f"{parts[0]}.{parts[1]}.{cluster}.{parts[2]}"
                    else:
                        # If can't fix, skip this standard
                        logger.warning(f"Skipping malformed standard ID: {std_id}")
                        continue

                # Clean standard text
                clean_text = re.sub(r'\s+', ' ', std_text).strip()

                # Remove the standard ID if it appears in the text
                clean_text = re.sub(rf'{re.escape(clean_id)}\s*', '', clean_text)

                # Remove common prefixes like "Standard: "
                clean_text = re.sub(r'^(Standard|Description):\s*', '', clean_text, flags=re.I)

                # Store the cleaned standard
                cleaned[clean_domain][clean_id] = clean_text

        return cleaned

    @retry(wait=wait_random_exponential(min=1, max=30), stop=stop_after_attempt(3))
    def generate_mcqs_for_standard(self, domain, standard_id, standard_text, num_questions=3):
        """
        Make some MCQs for a standard

        Args:
            domain (str): Domain name
            standard_id (str): Standard identifier
            standard_text (str): Standard description
            num_questions (int): Number of questions to generate

        Returns:
            list: Generated MCQs
        """
        # Added more personalized instructions to the prompt
        prompt = f"""
        I need {num_questions} high-quality multiple-choice questions for Grade {self.grade} students based on this Common Core Math standard:

        Domain: {domain}
        Standard ID: {standard_id}
        Standard: {standard_text}

        Also, for each question:
        1. Kindly create questions with varying difficulty levels (easy, medium, hard)
        2. Provide exactly 4 options labeled A, B, C, D
        3. Make distractors plausible but also clearly incorrect upon careful consideration
        4. Include a clear, concise explanation suitable for a Grade {self.grade} student
        5. Please ensure questions test conceptual understanding, not just memorization
        6. Make questions engaging and relatable to {self.grade}th grade students' everyday experiences

        Also, format each question as a JSON object with these fields:
        - "standard_id": The standard ID
        - "domain": The domain name
        - "question_text": The full question text
        - "options": List of objects with "label" (A, B, C, D) and "text" (option text)
        - "correct_answer": The letter of the correct answer
        - "explanation": Brief explanation of the correct answer
        - "difficulty": "easy", "medium", or "hard"

        Finally, return an array of {num_questions} question objects.
        """

        try:
            response = openai_chat(prompt, self.api_key)
            if not response:
                logger.error(f"Failed to generate MCQs for standard {standard_id}")
                return []

            # The response might be directly the array or nested under a key
            if isinstance(response, list):
                mcqs = response
            elif "questions" in response:
                mcqs = response["questions"]
            else:
                # Try to find an array in the response
                for key, value in response.items():
                    if isinstance(value, list) and len(value) > 0:
                        mcqs = value
                        break
                else:
                    logger.error(f"Unexpected response format for {standard_id}: {response}")
                    return []

            # Add domain if not present
            for mcq in mcqs:
                if "domain" not in mcq:
                    mcq["domain"] = domain

            return mcqs

        except Exception as e:
            logger.error(f"Error generating MCQs for {standard_id}: {e}")
            logger.error(f"Traceback: {type(e).__name__}: {e}")
            return []

    def generate_all_mcqs(self, standards=None, questions_per_standard=2):
        """
        Loop through standards and generate MCQs for all standards or provided standards.

        Args:
            standards (dict, optional): Standards to use. If None, use previously extracted standards
            questions_per_standard (int): Number of questions per standard

        Returns:
            list: All generated MCQs
        """
        if standards is None:
            standards = self.standards

        if not standards:
            logger.error("No standards available to generate MCQs")
            return []

        all_mcqs = []

        # Process domains with some prioritization to personalize the code
        domain_order = list(standards.keys())

        # Prioritize certain domains if they exist
        for priorityDomain in self.priorityDomains:
            for domain in domain_order:
                if priorityDomain.lower() in domain.lower():
                    # Move to front of list
                    domain_order.remove(domain)
                    domain_order.insert(0, domain)

        # Now process in the determined order
        for domain in domain_order:
            domain_standards = standards[domain]
            logger.info(f"Generating MCQs for domain: {domain} ({len(domain_standards)} standards)")

            for standard_id, standard_text in domain_standards.items():
                logger.info(f"Generating questions for {standard_id}")

                mcqs = self.generate_mcqs_for_standard(
                    domain,
                    standard_id,
                    standard_text,
                    num_questions=questions_per_standard
                )

                if mcqs:
                    all_mcqs.extend(mcqs)
                    logger.info(f"Generated {len(mcqs)} MCQs for {standard_id}")
                else:
                    logger.warning(f"Failed to generate MCQs for {standard_id}")

        self.mcqs = all_mcqs
        return all_mcqs

    def validate_mcq(self, mcq):
        """
        Validate a single MCQ for quality and correctness!

        Args:
            mcq (dict): MCQ to validate

        Returns:
            tuple: (is_valid, validation_result)
        """
        # Create options text for the prompt
        options_text = "\n".join(f"{opt['label']}. {opt['text']}" for opt in mcq['options'])

        prompt = f"""
        Plesae validate this Grade {self.grade} Math MCQ for quality and correctness:

        Domain: {mcq.get('domain', 'Unknown')}
        Standard ID: {mcq['standard_id']}
        Question: {mcq['question_text']}

        Options:
        {options_text}

        Correct Answer: {mcq['correct_answer']}
        Explanation: {mcq['explanation']}

        Evaluate based on these criteria:
        1. Accuracy - Is the marked answer truly correct?
        2. Clarity - Is the question clear and unambiguous?
        3. Grade-appropriateness - Is it suitable for Grade {self.grade}?
        4. Alignment - Does it test the cited standard?
        5. Quality of distractors - Are wrong answers plausible but clearly incorrect?

        Finally, return a JSON object with:
        - "is_valid": boolean (true/false)
        - "errors": array of specific issues found (empty if valid)
        - "suggestions": array of improvement suggestions
        - "corrected_answer": the correct option if different from provided (null if unchanged)
        """

        try:
            validation = openai_chat(prompt, self.api_key)

            if not validation:
                logger.warning(f"Failed to validate MCQ: {mcq['standard_id']}")
                return False, {"is_valid": False, "errors": ["Validation failed"]}

            is_valid = validation.get("is_valid", False)

            # Log validation results
            if is_valid:
                if validation.get("suggestions"):
                    logger.info(f"MCQ {mcq['standard_id']} valid with suggestions: {validation['suggestions']}")
                else:
                    logger.info(f"MCQ {mcq['standard_id']} passed validation")
            else:
                logger.warning(f"MCQ {mcq['standard_id']} failed validation: {validation.get('errors', ['Unknown error'])}")

            return is_valid, validation

        except Exception as e:
            logger.error(f"Error validating MCQ {mcq['standard_id']}: {e}")
            logger.error(f"Traceback: {type(e).__name__}: {e}")
            return False, {"is_valid": False, "errors": [str(e)]}

    def validate_all_mcqs(self):
        """
        Validate all generated MCQs.

        Returns:
            list: Validated MCQs
        """
        if not self.mcqs:
            logger.warning("No MCQs to validate")
            return []

        validated_mcqs = []
        invalid_mcqs = []

        logger.info(f"Validating {len(self.mcqs)} MCQs")

        for mcq in self.mcqs:
            is_valid, validation = self.validate_mcq(mcq)

            if is_valid:
                # Incorporating any suggestions into the MCQ
                if "suggestions" in validation and validation["suggestions"]:
                    mcq["improvement_suggestions"] = validation["suggestions"]

                # Updating the correct answer if validation found a different one
                if "corrected_answer" in validation and validation["corrected_answer"]:
                    mcq["correct_answer"] = validation["corrected_answer"]
                    logger.info(f"Corrected answer for MCQ {mcq['standard_id']}")

                validated_mcqs.append(mcq)
            else:
                mcq["validation_errors"] = validation.get("errors", ["Unknown error"])
                invalid_mcqs.append(mcq)

        logger.info(f"Validation complete: {len(validated_mcqs)} valid, {len(invalid_mcqs)} invalid")

        # Storing only valid MCQs
        self.mcqs = validated_mcqs
        return validated_mcqs

    def save_mcqs_to_file(self, filename="grade5_math_mcqs.json"):
        """
        Save generated MCQs to a JSON file.

        Args:
            filename (str): Output filename

        Returns:
            bool: True if successful, False otherwise
        """
        if not self.mcqs:
            logger.warning("No MCQs to save")
            return False

        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump({
                    "grade": self.grade,
                    "total_mcqs": len(self.mcqs),
                    "generated_date": datetime.now().strftime("%Y-%m-%d"),  # Today’s date
                    "mcqs": self.mcqs
                }, f, indent=2)

            logger.info(f"Saved {len(self.mcqs)} MCQs to {filename}")
            return True

        except Exception as e:
            logger.error(f"Error saving MCQs to file: {e}")
            logger.error(f"Traceback: {type(e).__name__}: {e}")
            return False

    def run_pipeline(self, questions_per_standard=2, use_fallback=False):
        """
        Tie it all together— fetch, generate, validate, save.

        Args:
            questions_per_standard (int): Number of questions to generate per standard
            use_fallback (bool): Whether to use fallback methods immediately

        Returns:
            bool: True if successful, False otherwise
        """
        # Step 1 & 2: Get standards (either from web or fallback)
        if use_fallback:
            # Skip web scraping and use LLM generation directly
            logger.info("Using fallback method to generate standards")
            self.standards = self.generate_standards_with_llm()
        else:
            # Try web scraping first
            logger.info("Attempting to fetch standards from the web")
            html_content = self.fetch_standards_page()

            if html_content:
                standards = self.extract_standards_with_soup(html_content)
                if standards:
                    self.standards = self.clean_standards(standards)
                else:
                    logger.warning("Web scraping failed to extract standards, using fallback")
                    self.standards = self.generate_standards_with_llm()
            else:
                logger.warning("Failed to fetch standards page, using fallback")
                self.standards = self.generate_standards_with_llm()

        if not self.standards:
            logger.error("Failed to get standards through any method")
            return False

        logger.info(f"Got {sum(len(domain_stds) for domain_stds in self.standards.values())} standards")

        # Step 3: Generate MCQs
        self.generate_all_mcqs(questions_per_standard=questions_per_standard)
        if not self.mcqs:
            logger.error("Failed to generate MCQs")
            return False

        # Step 4: Validate MCQs
        validated_mcqs = self.validate_all_mcqs()
        if not validated_mcqs:
            logger.error("No MCQs passed validation")
            return False

        # Step 5: Save results
        return self.save_mcqs_to_file()

#Main Execution
if __name__ == "__main__":
    # Get API key from environment or user input
    api_key = get_api_key()

    # Create generator instance
    mcq_gen = CommonCoreMCQGenerator(api_key=api_key, grade=5)

    try:
        # First attempt with web scraping
        logger.info("Attempting to run pipeline with web scraping")
        success = mcq_gen.run_pipeline(questions_per_standard=2)

        if not success:
            # If web scraping fails, try the fallback approach
            logger.info("Web scraping approach failed, switching to fallback method")
            success = mcq_gen.run_pipeline(questions_per_standard=2, use_fallback=True)

        if success:
            print(f"Successfully generated {len(mcq_gen.mcqs)} validated MCQs!")
            print(f"Output saved to grade5_math_mcqs.json")
        else:
            print("MCQ generation failed. Check logs for details.")
    except Exception as e:
        logger.error(f"Unhandled exception in main: {e}")
        logger.error(f"Traceback: {type(e).__name__}: {e}")
        print("An error occurred during execution. Check logs for details.")